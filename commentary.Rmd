---
title: ""
output: pdf_document
bibliography: bibliography.bib
editor_options: 
  
  chunk_output_type: console
---

#Commentary: it is a good idea to have bad ideas in science.

###Abstract
There are few truly bad ideas in authentic science. We need to embrace science as a process-driven human endeavour to better understand the world around us. Products are important, but through better transparency, we can leverage ideas, good and bad, ours and others, to do better science. In a brief commentary here inspired by a recent discussion of the topic and previous introspections by other ecologists, it is proposed that whilst it is a good idea to track ideas and all the processes that generate outcomes such as publications, there is inherent merit in all scientific ideas. That said, organizing and framing our ideas into the networks that we already use to examine hypotheses and questions in science is a window into our workflows including ideation, implementation, data analyses, and how we can better map ideas into open science outcomes. Formalizing and describing the linkages between ideas, data, and projects we produce as scientists will enhance and diversify the value of the work we do individually and collectively.

###Preamble  
A recent editorial suggests that science is all about sorting the wheat from the chaff [@Kirwan2017]. To be clear and fair, the author conceptualizes bad ideas using suggestions from eminent scientists on the value and necessity of bad ideas to the advancement of good science. It is concluded that successful science must embrace a pluralism of ideas and that it is not a waste of time to explore ideas that do not work out. The bad-idea science paradigm proposed is a simple dichotomy defining good ideas as those that generate publications and bad as those that do not. This is a functional taxonomy for the purposes of a self-assessment of work done (i.e. effort allocated) and project ideas by the author, and to the defence of this analysis, every effort was made to qualitatively include ideas that were 'built on' for subsequent positive outcomes, i.e. publications. This working definition is an absolutely necessary and convenient short-cut, but it is not the end of the story. The accountability of ideas to the progress of a discipline such as ecology is not a new idea [@Grime1993; @Weiner1995] nor without debate [@Aarssen1997; @Weiner1999]. Common ground suggests that we should individually evaluate the merit of our ideas if for no other reason then to better prepare our work for the review process of others. We can even conceptualize some of the less productive ideas as stepping stones to more useful ones or as a counterpoint to frame and anchor the relative merit of those that succeed in whatever capacity we elect to define the positive outcomes. Creation, divine or otherwise, is not a perfect system. Evolution needs mutations. That ideas are bad if they do not either directly or indirectly generate publications is perhaps too limiting. New ideas are novel, and new _and_ useful ideas are creative [@Runco2012]. The former can become the subtrate for the latter. Useless today can become indispensible tomorrow. Sorting the wheat from the chaff is an exercise in predicting an unknown landscape of discovery. Introspection of our workflows and the relationship between ideation and implementation will nonetheless streamline the mapping of ideas and hypotheses to effective testing through evidence. However, we also need to ensure that ideas do not get lost through self-criticism, lack of data, availability of a mechanism to test today, or through entanglement in the quagmire of of extensive information we process as scientists. In the spirit of replication science [@Brandt2014; @Mulkay1986], I examined my relative idea management and outcomes to explore whether this more generous interpretation of merit and my workflow kept most of the wheat and some of the chaff.  

###Replication      
A simplified, direct replication of the concept of idea merit self-assessement from the most recent editorial that inspired this commentary was done. A check of idea efficacy scrapes the files and structures used to support a scientific workflow (hosted locally, but see below on how this landscape is changing). This in and of itself is a superb idea. The need and pressure to publish can encourage one to be less cognizant of the processes that support the final paper particularly if there are many steps or if time to final acceptance is significant [@Powell2016]. Many of the simple rules for data and experimental provenance [@Kazic2015] also apply to what can be similarly termed 'scientific idea provenance' including version control, integration, object labelling, and reviewing the semantics. The author in the former idea provenance self-study examined all projects completed in career, recorded initiation date, scored effort for each, and developed an outcome classification scale that included direct and indirect publications from each project [@Kirwan2017]. A project was defined as a 'project folder' that likely represented parent directories organized around each independent research thread. The author concluded that 25% of projects generated a publishable result. The assumption of this workflow is that every scientific task is assigned to/nested within a project folder. The folder dimension of my scientific workflows is similar but not a perfect match (and it is fundamentally evolving). I use project folders to organize protocols and ideas, dataset folders for data and some other forms of scientific evidence such as camera trap pictures, an 'idea archive' parent folder to store all ideas, and a 'papers-in-progress' parent folder with subfolders to store ideas that have some development in written form. However, this workflow and structure for organzing the processes that support scientific inquiry is dramatically changing thanks to GitHub and RStudio where I couple code, annotation, and written interpretations with the associated datasets. Scoring effort and time allocated, pre-Github and without effective, time-stamped version control was not viable in terms of reproducibility with my former workflow and its files. Consequently, I restricted analyses primarily to counts. However, I propose that the number of objects within a project, i.e. files, in addition to parent/child folders that support a research thread is an important building block in many instances in the process of turning ideas into more tangible outcomes. This conceptualization of project workflows more fully embraces a provenance paradigm for ideas. Hence, I use a more topological approach to model the merit of ideas herein but expanded the supporting structures associated with ideas and workflows. The diversity of outcomes can also be expanded to recognize open science products published online such as datasets in recognized repositories, slide decks in hosting services, and code that supports data and traditional publications.  

  
  
To provide context for the idea provenance self-study, I did a scrape of scientific outcomes published online. Papers were recorded as positive outcomes if in print with a peer-reviewed journal, but pre-prints were excluded to avoid non-independence issues. The count of papers was the primary outcome used as the denominator in the previous examination [@Kirwan2017]. Datasets published with a DOI in a repository, open slide decks published online with a recognized sharing service, independent repositories with code and data posted to GitHub, and other open science products such as conceptual figures on figshare were also recorded. Total number of independent ideas stored within a parent directory on my local HD were also included in this examination as an estimate of the total available seed pool for all these public outcomes. This more inclusive, open science perspective on outcomes showed that traditional peer-reviewed papers ranked second after the general open science products (slide decks and figures) category (Figure 1). This is likely representative of many scientists because we give many talks, and if a slide deck were posted online for many of them, it would exceed the number of publications. Conceptual figures or scientific cartoons are also likely common because many scientists turn predictions or ideas into a theoretical plot to visualize a relationship during the experimental design phase of a project. Many of these visual predictions are unsupported but faciliate sketching out the ideas for the final publication. Finally, the total count of all ideas that I allocated time to record and formally capture as an individual note within the parent folder I termed my 'idea archive' (that is certainly not a Sherlockian mind palace) nearly tripled my papers published. In my experiences within working groups, this is within the range of ideas proposed and formally captured in some written capacity. Many more ideas are wildly sown in these collaboratively endeavours but the even the germination rate drops to similar levels within my personal workflow.

![Scientific outcomes published online and ideas captured locally within a collective career-level scrape of productivity for an ecologist. See text for full description of each scientific element class.](./fig1.png)  

###Implications  
Am I a good idea farmer?
Need a venue for ideas that provides both recognition, context via tags, and discoverablility by others. We currently use social media, conference presentations, and a few other channels to share ideas but aggregation and searchability is important. An idea respository like we have for data is just as important, perhaps more so, as a substrate for the advancement of science.

\newpage
###Literature cited